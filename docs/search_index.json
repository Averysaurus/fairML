[
["index.html", "Fairness and Bias in Machine Learning Workshop Chapter 1 Redoing ProPublica Analysis of the COMPAS dataset", " Fairness and Bias in Machine Learning Workshop Jae Yeon Kim Aniket Kesari Renata Barreto Avery Richard 2020-10-07 Chapter 1 Redoing ProPublica Analysis of the COMPAS dataset We have revised the ProPublica’s Analysis of the COMPAS dataset to increase code readability and make changing data analysis and visualization easier. Bias in the data Logistic regression analysis Risk of Recidivism Data Risk of Violent Recidivism Data Bias in the algorithm Survival analysis For more information on the ProPublica’s Machine Bias project, I encourage to check out this article. Argument by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner Counterargument by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel Methodology Original Notebook in R "],
["risk-of-recidivism-analysis.html", "Chapter 2 Risk of recidivism analysis 2.1 Setup 2.2 Load data 2.3 Wrangling 2.4 Descriptive analysis 2.5 Modeling", " Chapter 2 Risk of recidivism analysis 2.1 Setup if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman pacman::p_load( tidyverse, # tidyverse packages conflicted, # an alternative conflict resolution strategy patchwork, # arranging ggplots scales, # rescaling survival, # survival analysis broom, # for modeling here, # reproducibility glue # pasting strings and objects ) # To avoid conflicts conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::filter over any other package conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::select over any other package 2.2 Load data We select fields for severity of charge, number of priors, demographics, age, sex, COMPAS scores, and whether each person was accused of a crime within two years. N of observations (rows): 7,214 N of variables (columns): 53 two_years &lt;- read_csv(here(&quot;data&quot;, &quot;compas-scores-two-years.csv&quot;)) ## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt; ## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49] dim(two_years) ## [1] 7214 53 2.3 Wrangling Not all of the observations are useable for the first round of analysis. There are a number of reasons to remove rows because of missing data: If the charge date of a defendants COMPAS scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense. We coded the recidivist flag – is_recid – to be -1 if we could not find a COMPAS case at all. In a similar vein, ordinary traffic offenses – those with a c_charge_degree of ‘O’ – will not result in Jail time are removed (only two of them). We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility. 2.3.1 Create a function wrangle_data &lt;- function(data){ df &lt;- data %&gt;% # Select variables select(age, c_charge_degree, race, age_cat, score_text, sex, priors_count, days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %&gt;% # Filter rows filter(days_b_screening_arrest &lt;= 30, days_b_screening_arrest &gt;= -30, is_recid != -1, c_charge_degree != &quot;O&quot;, score_text != &#39;N/A&#39;) %&gt;% # Mutate variables mutate(length_of_stay = as.numeric(as.Date(c_jail_out) - as.Date(c_jail_in)), c_charge_degree = factor(c_charge_degree), age_cat = factor(age_cat), race = factor(race, levels = c(&quot;Caucasian&quot;,&quot;African-American&quot;,&quot;Hispanic&quot;,&quot;Other&quot;,&quot;Asian&quot;,&quot;Native American&quot;)), sex = factor(sex, levels = c(&quot;Male&quot;,&quot;Female&quot;)), score_text = factor(score_text, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;)), score = score_text, # I added this new variable to test whether measuring the DV as a binary or continuous var makes a difference score_num = as.numeric(score_text)) %&gt;% # Rename variables rename(crime = c_charge_degree, gender = sex) return(df)} 2.3.2 Apply the function to the data df &lt;- wrangle_data(two_years) names(df) ## [1] &quot;age&quot; &quot;crime&quot; ## [3] &quot;race&quot; &quot;age_cat&quot; ## [5] &quot;score_text&quot; &quot;gender&quot; ## [7] &quot;priors_count&quot; &quot;days_b_screening_arrest&quot; ## [9] &quot;decile_score&quot; &quot;is_recid&quot; ## [11] &quot;two_year_recid&quot; &quot;c_jail_in&quot; ## [13] &quot;c_jail_out&quot; &quot;length_of_stay&quot; ## [15] &quot;score&quot; &quot;score_num&quot; # Check whether the function works as expected head(df, 5) ## # A tibble: 5 x 16 ## age crime race age_cat score_text gender priors_count days_b_screenin… ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 69 F Other Greate… Low Male 0 -1 ## 2 34 F Afri… 25 - 45 Low Male 0 -1 ## 3 24 F Afri… Less t… Low Male 4 -1 ## 4 44 M Other 25 - 45 Low Male 0 0 ## 5 41 F Cauc… 25 - 45 Medium Male 14 -1 ## # … with 8 more variables: decile_score &lt;dbl&gt;, is_recid &lt;dbl&gt;, ## # two_year_recid &lt;dbl&gt;, c_jail_in &lt;dttm&gt;, c_jail_out &lt;dttm&gt;, ## # length_of_stay &lt;dbl&gt;, score &lt;fct&gt;, score_num &lt;dbl&gt; 2.4 Descriptive analysis Higher COMPAS scores are slightly correlated with a longer length of stay. cor(df$length_of_stay, df$decile_score) ## [1] 0.2073297 # Set theme ggplot2::theme_set(theme_minimal()) df %&gt;% group_by(score) %&gt;% count() %&gt;% ggplot(aes(x = score, y = n)) + geom_col() + labs(x = &quot;Score&quot;, y = &quot;Count&quot;, title = &quot;Score distribution&quot;) Judges are often presented with two sets of scores from the COMPAS system – one that classifies people into High, Medium and Low risk, and a corresponding decile score. There is a clear downward trend in the decile scores as those scores increase for white defendants. df %&gt;% ggplot(aes(ordered(decile_score))) + geom_bar() + facet_wrap(~race, nrow = 2) + labs(x = &quot;Decile Score&quot;, y = &quot;Count&quot;, Title = &quot;Defendant&#39;s Decile Score&quot;) 2.5 Modeling After filtering out bad rows, our first question is whether there is a significant difference in COMPAS scores between races. To do so we need to change some variables into factors, and run a logistic regression, comparing low scores to high scores. 2.5.1 Model building model_data &lt;- function(data){ # Logistic regression model lr_model &lt;- glm(score ~ gender + age_cat + race + priors_count + crime + two_year_recid, family = &quot;binomial&quot;, data = data) # OLS, DV = score_num ols_model1 &lt;- lm(score_num ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) # OLS, DV = decile_score ols_model2 &lt;- lm(decile_score ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) # Extract model outcomes with confidence intervals lr_est &lt;- lr_model %&gt;% tidy(conf.int = TRUE) ols_est1 &lt;- ols_model1 %&gt;% tidy(conf.int = TRUE) ols_est2 &lt;- ols_model2 %&gt;% tidy(conf.int = TRUE) # AIC scores lr_AIC &lt;- AIC(lr_model) ols_AIC1 &lt;- AIC(ols_model1) ols_AIC2 &lt;- AIC(ols_model2) list(lr_est, ols_est1, ols_est2, lr_AIC, ols_AIC1, ols_AIC2) } 2.5.2 Model comparisons glue(&quot;AIC score of logistic regression: {model_data(df)[4]} AIC score of OLS regression (with categorical DV): {model_data(df)[5]} AIC score of OLS regression (with continuous DV): {model_data(df)[6]}&quot;) ## AIC score of logistic regression: 6192.40169473357 ## AIC score of OLS regression (with categorical DV): 11772.1148541111 ## AIC score of OLS regression (with continuous DV): 26779.9512226999 2.5.3 Logistic regression model lr_model &lt;- model_data(df)[1] %&gt;% data.frame() lr_model %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender|M&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, estimate), y = estimate, ymax = conf.high, ymin = conf.low)) + geom_pointrange() + coord_flip() + labs(y = &quot;Estimate&quot;, x = &quot;&quot;, title = &quot;Logistic regression&quot;) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) interpret_estimate &lt;- function(model){ # Control intercept &lt;- model$estimate[model$term == &quot;(Intercept)&quot;] control &lt;- exp(intercept) / (1 + exp(intercept)) # Likelihood model &lt;- model %&gt;% filter(term != &quot;(Intercept)&quot;) model$likelihood &lt;- (exp(model$estimate) / (1 - control + (control * exp(model$estimate)))) return(model) } interpret_estimate(lr_model) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, likelihood), y = likelihood)) + geom_point(size = 3) + coord_flip() + labs(y = &quot;Likelihood&quot;, x = &quot;&quot;, title =&quot;Logistic regression&quot;) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + geom_hline(yintercept = 1, linetype = &quot;dashed&quot;) "]
]
