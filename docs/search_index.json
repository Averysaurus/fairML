[["index.html", "Fairness and Bias in Machine Learning Workshop Chapter 1 Redoing ProPublica’s Analysis of the COMPAS dataset", " Fairness and Bias in Machine Learning Workshop Jae Yeon Kim Aniket Kesari Renata Barreto Avery Richard 2020-10-16 Chapter 1 Redoing ProPublica’s Analysis of the COMPAS dataset This Fairness and Bias in Machine Learning workshop has revised the ProPublica’s Analysis of the COMPAS dataset to increase code readability and blend it with other references. Bias in the data Logistic regression analysis Risk of Recidivism Data Risk of Violent Recidivism Data Bias in the algorithm Survival analysis For more information on the ProPublica’s Machine Bias project, I encourage to check out this article. Argument by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner Counterargument by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel Methodology Original Notebook in R "],["bias-in-the-data-risk-of-recidivism-analysis.html", "Chapter 2 Bias in the Data (Risk of Recidivism Analysis) 2.1 Setup 2.2 Load data 2.3 Wrangling 2.4 Descriptive analysis 2.5 Modeling", " Chapter 2 Bias in the Data (Risk of Recidivism Analysis) 2.1 Setup if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman pacman::p_load( tidyverse, # tidyverse packages conflicted, # an alternative conflict resolution strategy ggthemes, # other themes for ggplot2 patchwork, # arranging ggplots scales, # rescaling survival, # survival analysis broom, # for modeling here, # reproducibility glue # pasting strings and objects ) # To avoid conflicts conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::filter over any other package conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::select over any other package # Set themes theme_set(ggthemes::theme_fivethirtyeight()) 2.2 Load data We select fields for severity of charge, number of priors, demographics, age, sex, COMPAS scores, and whether each person was accused of a crime within two years. two_years &lt;- read_csv(here(&quot;data&quot;, &quot;compas-scores-two-years.csv&quot;)) ## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt; ## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49] glue(&quot;N of observations (rows): {nrow(two_years)} N of variables (columns): {ncol(two_years)}&quot;) ## N of observations (rows): 7214 ## N of variables (columns): 53 2.3 Wrangling Not all of the observations are useable for the first round of analysis. There are a number of reasons to remove rows because of missing data: If the charge date of a defendants COMPAS scored crime was not within 30 days from when the person was arrested, we assume that because of data quality reasons, that we do not have the right offense. We coded the recidivist flag – is_recid – to be -1 if we could not find a COMPAS case at all. In a similar vein, ordinary traffic offenses – those with a c_charge_degree of ‘O’ – will not result in Jail time are removed (only two of them). We filtered the underlying data from Broward county to include only those rows representing people who had either recidivated in two years, or had at least two years outside of a correctional facility. 2.3.1 Create a function wrangle_data &lt;- function(data){ df &lt;- data %&gt;% # Select variables select(age, c_charge_degree, race, age_cat, score_text, sex, priors_count, days_b_screening_arrest, decile_score, is_recid, two_year_recid, c_jail_in, c_jail_out) %&gt;% # Filter rows filter(days_b_screening_arrest &lt;= 30, days_b_screening_arrest &gt;= -30, is_recid != -1, c_charge_degree != &quot;O&quot;, score_text != &#39;N/A&#39;) %&gt;% # Mutate variables mutate(length_of_stay = as.numeric(as.Date(c_jail_out) - as.Date(c_jail_in)), c_charge_degree = factor(c_charge_degree), age_cat = factor(age_cat), race = factor(race, levels = c(&quot;Caucasian&quot;,&quot;African-American&quot;,&quot;Hispanic&quot;,&quot;Other&quot;,&quot;Asian&quot;,&quot;Native American&quot;)), sex = factor(sex, levels = c(&quot;Male&quot;,&quot;Female&quot;)), score_text = factor(score_text, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;)), score = score_text, # I added this new variable to test whether measuring the DV as a binary or continuous var makes a difference score_num = as.numeric(score_text)) %&gt;% # Rename variables rename(crime = c_charge_degree, gender = sex) return(df)} 2.3.2 Apply the function to the data df &lt;- wrangle_data(two_years) names(df) ## [1] &quot;age&quot; &quot;crime&quot; ## [3] &quot;race&quot; &quot;age_cat&quot; ## [5] &quot;score_text&quot; &quot;gender&quot; ## [7] &quot;priors_count&quot; &quot;days_b_screening_arrest&quot; ## [9] &quot;decile_score&quot; &quot;is_recid&quot; ## [11] &quot;two_year_recid&quot; &quot;c_jail_in&quot; ## [13] &quot;c_jail_out&quot; &quot;length_of_stay&quot; ## [15] &quot;score&quot; &quot;score_num&quot; # Check whether the function works as expected head(df, 5) ## # A tibble: 5 x 16 ## age crime race age_cat score_text gender priors_count days_b_screenin… ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 69 F Other Greate… Low Male 0 -1 ## 2 34 F Afri… 25 - 45 Low Male 0 -1 ## 3 24 F Afri… Less t… Low Male 4 -1 ## 4 44 M Other 25 - 45 Low Male 0 0 ## 5 41 F Cauc… 25 - 45 Medium Male 14 -1 ## # … with 8 more variables: decile_score &lt;dbl&gt;, is_recid &lt;dbl&gt;, ## # two_year_recid &lt;dbl&gt;, c_jail_in &lt;dttm&gt;, c_jail_out &lt;dttm&gt;, ## # length_of_stay &lt;dbl&gt;, score &lt;fct&gt;, score_num &lt;dbl&gt; 2.4 Descriptive analysis Higher COMPAS scores are slightly correlated with a longer length of stay. cor(df$length_of_stay, df$decile_score) ## [1] 0.2073297 df %&gt;% group_by(score) %&gt;% count() %&gt;% ggplot(aes(x = score, y = n)) + geom_col() + labs(x = &quot;Score&quot;, y = &quot;Count&quot;, title = &quot;Score distribution&quot;) Judges are often presented with two sets of scores from the COMPAS system – one that classifies people into High, Medium and Low risk, and a corresponding decile score. There is a clear downward trend in the decile scores as those scores increase for white defendants. df %&gt;% ggplot(aes(ordered(decile_score))) + geom_bar() + facet_wrap(~race, nrow = 2) + labs(x = &quot;Decile Score&quot;, y = &quot;Count&quot;, Title = &quot;Defendant&#39;s Decile Score&quot;) 2.5 Modeling After filtering out bad rows, our first question is whether there is a significant difference in COMPAS scores between races. To do so we need to change some variables into factors, and run a logistic regression, comparing low scores to high scores. 2.5.1 Model building model_data &lt;- function(data){ # Logistic regression model lr_model &lt;- glm(score ~ gender + age_cat + race + priors_count + crime + two_year_recid, family = &quot;binomial&quot;, data = data) # OLS, DV = score_num ols_model1 &lt;- lm(score_num ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) # OLS, DV = decile_score ols_model2 &lt;- lm(decile_score ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) # Extract model outcomes with confidence intervals lr_est &lt;- lr_model %&gt;% tidy(conf.int = TRUE) ols_est1 &lt;- ols_model1 %&gt;% tidy(conf.int = TRUE) ols_est2 &lt;- ols_model2 %&gt;% tidy(conf.int = TRUE) # AIC scores lr_AIC &lt;- AIC(lr_model) ols_AIC1 &lt;- AIC(ols_model1) ols_AIC2 &lt;- AIC(ols_model2) list(lr_est, ols_est1, ols_est2, lr_AIC, ols_AIC1, ols_AIC2) } 2.5.2 Model comparisons glue(&quot;AIC score of logistic regression: {model_data(df)[4]} AIC score of OLS regression (with categorical DV): {model_data(df)[5]} AIC score of OLS regression (with continuous DV): {model_data(df)[6]}&quot;) ## AIC score of logistic regression: 6192.40169473357 ## AIC score of OLS regression (with categorical DV): 11772.1148541111 ## AIC score of OLS regression (with continuous DV): 26779.9512226999 2.5.3 Logistic regression model lr_model &lt;- model_data(df)[1] %&gt;% data.frame() lr_model %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender|M&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, estimate), y = estimate, ymax = conf.high, ymin = conf.low)) + geom_pointrange() + coord_flip() + labs(y = &quot;Estimate&quot;, x = &quot;&quot;, title = &quot;Logistic regression&quot;) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) interpret_estimate &lt;- function(model){ # Control intercept &lt;- model$estimate[model$term == &quot;(Intercept)&quot;] control &lt;- exp(intercept) / (1 + exp(intercept)) # Likelihood model &lt;- model %&gt;% filter(term != &quot;(Intercept)&quot;) model$likelihood &lt;- (exp(model$estimate) / (1 - control + (control * exp(model$estimate)))) return(model) } interpret_estimate(lr_model) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, likelihood), y = likelihood)) + geom_point(size = 3) + coord_flip() + labs(y = &quot;Likelihood&quot;, x = &quot;&quot;, title =&quot;Logistic regression&quot;) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + geom_hline(yintercept = 1, linetype = &quot;dashed&quot;) "],["bias-in-the-data-risk-of-violent-recidivism-analysis.html", "Chapter 3 Bias in the Data (Risk of Violent Recidivism Analysis) 3.1 Setup 3.2 Load data 3.3 Wrangling", " Chapter 3 Bias in the Data (Risk of Violent Recidivism Analysis) 3.1 Setup if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman pacman::p_load( tidyverse, # tidyverse packages conflicted, # an alternative conflict resolution strategy ggthemes, # other themes for ggplot2 patchwork, # arranging ggplots scales, # rescaling survival, # survival analysis broom, # for modeling here, # reproducibility glue # pasting strings and objects ) # To avoid conflicts conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::filter over any other package conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::select over any other package # Set themes theme_set(ggthemes::theme_fivethirtyeight()) 3.2 Load data two_years_violent &lt;- read_csv(here(&quot;data&quot; ,&quot;compas-scores-two-years-violent.csv&quot;)) ## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt; ## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49], &#39;two_year_recid&#39; ## =&gt; &#39;two_year_recid_1&#39; [54] ## ## ── Column specification ─────────────────────── ## cols( ## .default = col_double(), ## name = col_character(), ## first = col_character(), ## last = col_character(), ## compas_screening_date = col_date(format = &quot;&quot;), ## sex = col_character(), ## dob = col_date(format = &quot;&quot;), ## age_cat = col_character(), ## race = col_character(), ## c_jail_in = col_datetime(format = &quot;&quot;), ## c_jail_out = col_datetime(format = &quot;&quot;), ## c_case_number = col_character(), ## c_offense_date = col_date(format = &quot;&quot;), ## c_arrest_date = col_date(format = &quot;&quot;), ## c_charge_degree = col_character(), ## c_charge_desc = col_character(), ## r_case_number = col_character(), ## r_charge_degree = col_character(), ## r_offense_date = col_date(format = &quot;&quot;), ## r_charge_desc = col_character(), ## r_jail_in = col_date(format = &quot;&quot;) ## # ... with 14 more columns ## ) ## ℹ Use `spec()` for the full column specifications. glue(&quot;N of observations (rows): {nrow(two_years_violent)} N of variables (columns): {ncol(two_years_violent)}&quot;) ## N of observations (rows): 4743 ## N of variables (columns): 54 3.3 Wrangling 3.3.1 Create a function wrangle_data &lt;- function(data){ df &lt;- data %&gt;% # Select variables select(age, c_charge_degree, race, age_cat, v_score_text, sex, priors_count, days_b_screening_arrest, v_decile_score, is_recid, two_year_recid) %&gt;% # Filter rows filter(days_b_screening_arrest &lt;= 30, days_b_screening_arrest &gt;= -30, is_recid != -1, c_charge_degree != &quot;O&quot;, v_score_text != &#39;N/A&#39;) %&gt;% # Mutate variables mutate(c_charge_degree = factor(c_charge_degree), age_cat = factor(age_cat), race = factor(race, levels = c(&quot;Caucasian&quot;,&quot;African-American&quot;,&quot;Hispanic&quot;,&quot;Other&quot;,&quot;Asian&quot;,&quot;Native American&quot;)), sex = factor(sex, levels = c(&quot;Male&quot;,&quot;Female&quot;)), v_score_text = factor(v_score_text, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;)), # I added this new variable to test whether measuring the DV as a binary or continuous var makes a difference score_num = as.numeric(v_score_text)) %&gt;% # Rename variables rename(crime = c_charge_degree, gender = sex, score = v_score_text) return(df)} 3.3.2 Apply the function to the data df &lt;- wrangle_data(two_years_violent) names(df) ## [1] &quot;age&quot; &quot;crime&quot; ## [3] &quot;race&quot; &quot;age_cat&quot; ## [5] &quot;score&quot; &quot;gender&quot; ## [7] &quot;priors_count&quot; &quot;days_b_screening_arrest&quot; ## [9] &quot;v_decile_score&quot; &quot;is_recid&quot; ## [11] &quot;two_year_recid&quot; &quot;score_num&quot; head(df, 5) # Check whether the function works as expected ## # A tibble: 5 x 12 ## age crime race age_cat score gender priors_count days_b_screenin… ## &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 69 F Other Greate… Low Male 0 -1 ## 2 34 F Afri… 25 - 45 Low Male 0 -1 ## 3 44 M Other 25 - 45 Low Male 0 0 ## 4 43 F Other 25 - 45 Low Male 3 -1 ## 5 39 M Cauc… 25 - 45 Low Female 0 -1 ## # … with 4 more variables: v_decile_score &lt;dbl&gt;, is_recid &lt;dbl&gt;, ## # two_year_recid &lt;dbl&gt;, score_num &lt;dbl&gt; 3.3.3 Descriptive analysis Score distribution df %&gt;% group_by(score) %&gt;% count() %&gt;% ggplot(aes(x = score, y = n)) + geom_col() + labs(x = &quot;Score&quot;, y = &quot;Count&quot;, title = &quot;Score distribution&quot;) Score distribution by race df %&gt;% ggplot(aes(ordered(v_decile_score))) + geom_bar() + facet_wrap(~race, nrow = 2) + labs(x = &quot;Decile Score&quot;, y = &quot;Count&quot;, Title = &quot;Defendant&#39;s Decile Score&quot;) 3.3.4 Modeling After filtering out bad rows, our first question is whether there is a significant difference in COMPAS scores between races. To do so we need to change some variables into factors, and run a logistic regression, comparing low scores to high scores. model_data &lt;- function(data){ # Logistic regression model lr_model &lt;- glm(score ~ gender + age_cat + race + priors_count + crime + two_year_recid, family = &quot;binomial&quot;, data = data) # OLS ols_model1 &lt;- lm(score_num ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) ols_model2 &lt;- lm(v_decile_score ~ gender + age_cat + race + priors_count + crime + two_year_recid, data = data) # Extract model outcomes with confidence intervals lr_est &lt;- lr_model %&gt;% tidy(conf.int = TRUE) ols_est1 &lt;- ols_model1 %&gt;% tidy(conf.int = TRUE) ols_est2 &lt;- ols_model2 %&gt;% tidy(conf.int = TRUE) # AIC scores lr_AIC &lt;- AIC(lr_model) ols_AIC1 &lt;- AIC(ols_model1) ols_AIC2 &lt;- AIC(ols_model2) list(lr_est, ols_est1, ols_est2, lr_AIC, ols_AIC1, ols_AIC2) } 3.3.4.1 Model comparisons glue(&quot;AIC score of logistic regression: {model_data(df)[4]} AIC score of OLS regression (with categorical DV): {model_data(df)[5]} AIC score of OLS regression (with continuous DV): {model_data(df)[6]}&quot;) ## AIC score of logistic regression: 3022.77943765996 ## AIC score of OLS regression (with categorical DV): 5414.49127581608 ## AIC score of OLS regression (with continuous DV): 15458.3861723106 3.3.4.2 Logistic regression model lr_model &lt;- model_data(df)[1] %&gt;% data.frame() lr_model %&gt;% filter(term != &quot;(Intercept)&quot;) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, estimate), y = estimate, ymax = conf.high, ymin = conf.low)) + geom_pointrange() + coord_flip() + labs(y = &quot;Estimate&quot;, x = &quot;&quot;, title = &quot;Logistic regression&quot;) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;) interpret_estimate &lt;- function(model){ # Control intercept &lt;- model$estimate[model$term == &quot;(Intercept)&quot;] control &lt;- exp(intercept) / (1 + exp(intercept)) # Likelihood model &lt;- model %&gt;% filter(term != &quot;(Intercept)&quot;) model$likelihood &lt;- (exp(model$estimate) / (1 - control + (control * exp(model$estimate)))) return(model) } interpret_estimate(lr_model) %&gt;% mutate(term = gsub(&quot;race|age_cat|gender&quot;,&quot;&quot;, term)) %&gt;% ggplot(aes(x = fct_reorder(term, likelihood), y = likelihood)) + geom_point(size = 3) + coord_flip() + labs(y = &quot;Likelihood&quot;, x = &quot;&quot;, title =&quot;Logistic regression&quot;) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + geom_hline(yintercept = 1, linetype = &quot;dashed&quot;) "],["bias-in-the-algorithm.html", "Chapter 4 Bias in the algorithm 4.1 Setup 4.2 Load data 4.3 Wrangling 4.4 Modeling", " Chapter 4 Bias in the algorithm In order to test whether COMPAS scores do an accurate job of deciding whether an offender is Low, Medium or High risk, we ran a Cox Proportional Hazards model. Northpointe, the company that created COMPAS and markets it to Law Enforcement, also ran a Cox model in their validation study. We used the counting model and removed people when they were incarcerated. Due to errors in the underlying jail data, we need to filter out 32 rows that have an end date more than the start date. Considering that there are 13,334 total rows in the data, such a small amount of errors will not affect the results. 4.1 Setup if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) ## Loading required package: pacman pacman::p_load( tidyverse, # tidyverse packages conflicted, # an alternative conflict resolution strategy ggthemes, # other themes for ggplot2 patchwork, # arranging ggplots scales, # rescaling survival, # survival analysis broom, # for modeling here, # reproducibility glue, # pasting strings and objects reticulate # source python codes ) # To avoid conflicts conflict_prefer(&quot;filter&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::filter over any other package conflict_prefer(&quot;select&quot;, &quot;dplyr&quot;) ## [conflicted] Will prefer dplyr::select over any other package # Set themes theme_set(ggthemes::theme_fivethirtyeight()) 4.2 Load data cox_data &lt;- read_csv(here(&quot;data&quot; ,&quot;cox-parsed.csv&quot;)) ## Warning: Duplicated column names deduplicated: &#39;decile_score&#39; =&gt; ## &#39;decile_score_1&#39; [40], &#39;priors_count&#39; =&gt; &#39;priors_count_1&#39; [49] ## ## ── Column specification ─────────────────────── ## cols( ## .default = col_character(), ## id = col_double(), ## compas_screening_date = col_date(format = &quot;&quot;), ## dob = col_date(format = &quot;&quot;), ## age = col_double(), ## juv_fel_count = col_double(), ## decile_score = col_double(), ## juv_misd_count = col_double(), ## juv_other_count = col_double(), ## priors_count = col_double(), ## days_b_screening_arrest = col_double(), ## c_jail_in = col_datetime(format = &quot;&quot;), ## c_jail_out = col_datetime(format = &quot;&quot;), ## c_offense_date = col_date(format = &quot;&quot;), ## c_arrest_date = col_date(format = &quot;&quot;), ## c_days_from_compas = col_double(), ## is_recid = col_double(), ## r_days_from_arrest = col_double(), ## r_offense_date = col_date(format = &quot;&quot;), ## r_jail_in = col_date(format = &quot;&quot;), ## r_jail_out = col_date(format = &quot;&quot;) ## # ... with 13 more columns ## ) ## ℹ Use `spec()` for the full column specifications. glue(&quot;N of observations (rows): {nrow(cox_data)} N of variables (columns): {ncol(cox_data)}&quot;) ## N of observations (rows): 13419 ## N of variables (columns): 52 4.3 Wrangling df &lt;- cox_data %&gt;% filter(score_text != &quot;N/A&quot;) %&gt;% filter(end &gt; start) %&gt;% mutate(c_charge_degree = factor(c_charge_degree), age_cat = factor(age_cat), race = factor(race, levels = c(&quot;Caucasian&quot;,&quot;African-American&quot;,&quot;Hispanic&quot;,&quot;Other&quot;,&quot;Asian&quot;,&quot;Native American&quot;)), sex = factor(sex, levels = c(&quot;Male&quot;,&quot;Female&quot;)), score_factor = factor(score_text, levels = c(&quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;))) grp &lt;- df[!duplicated(df$id),] 4.3.1 Descriptive analysis Score distribution grp %&gt;% group_by(score_factor) %&gt;% count() %&gt;% ggplot(aes(x = score_factor, y = n)) + geom_col() + labs(x = &quot;Score&quot;, y = &quot;Count&quot;, title = &quot;Score distribution&quot;) Score distribution by race df %&gt;% ggplot(aes(ordered(score_factor))) + geom_bar() + facet_wrap(~race, nrow = 2) + labs(x = &quot;Decile Score&quot;, y = &quot;Count&quot;, Title = &quot;Defendant&#39;s Decile Score&quot;) 4.4 Modeling f2 &lt;- Surv(start, end, event, type=&quot;counting&quot;) ~ race + score_factor + race * score_factor model &lt;- coxph(f2, data = df) model %&gt;% broom::tidy(conf.int = TRUE) %&gt;% mutate(term = gsub(&quot;race|score_factor&quot;,&quot;&quot;, term)) %&gt;% filter(term != &quot;&lt;chr&gt;&quot;) %&gt;% ggplot(aes(x = fct_reorder(term, estimate), y = estimate, ymax = conf.high, ymin = conf.low)) + geom_pointrange() + coord_flip() + labs(y = &quot;Estimate&quot;, x = &quot;&quot;) The interaction term shows a similar disparity as the logistic regression above. High risk white defendants are 3.61 more likely than low risk white defendants, while High risk black defendants are 2.99 more likely than low. visualize_surv &lt;- function(input){ f &lt;- Surv(start, end, event, type=&quot;counting&quot;) ~ score_factor fit &lt;- survfit(f, data = input) fit %&gt;% tidy(conf.int = TRUE) %&gt;% mutate(strata = gsub(&quot;score_factor=&quot;,&quot;&quot;, strata)) %&gt;% mutate(strata = factor(strata, levels = c(&quot;High&quot;,&quot;Medium&quot;,&quot;Low&quot;))) %&gt;% ggplot(aes(x = time, y = estimate, ymax = conf.high, ymin = conf.low, group = strata, col = strata)) + geom_pointrange(alpha = 0.1) + guides(colour = guide_legend(override.aes = list(alpha = 1))) + ylim(c(0, 1)) + labs(x = &quot;Time&quot;, y = &quot;Estimated survival rate&quot;, col = &quot;Strata&quot;)} visualize_surv(df) + ggtitle(&quot;Overall&quot;) Black defendants do recidivate at higher rates according to race specific Kaplan Meier plots. (df %&gt;% filter(race == &quot;Caucasian&quot;) %&gt;% visualize_surv() + ggtitle(&quot;Caucasian&quot;)) / (df %&gt;% filter(race == &quot;African-American&quot;) %&gt;% visualize_surv() + ggtitle(&quot;African-American&quot;)) In terms of underlying recidivism rates, we can look at gender specific Kaplan Meier estimates. There is a striking difference between women and men. (df %&gt;% filter(sex == &quot;Female&quot;) %&gt;% visualize_surv() + ggtitle(&quot;Female&quot;)) / (df %&gt;% filter(sex == &quot;Male&quot;) %&gt;% visualize_surv() + ggtitle(&quot;Male&quot;)) As these plots show, the COMPAS score treats a High risk women the same as a Medium risk man. 4.4.1 Risk of Recidivism accuracy The above analysis shows that the COMPAS algorithm does overpredict African-American defendant’s future recidivism, but we haven’t yet explored the direction of the bias. We can discover fine differences in overprediction and underprediction by comparing COMPAS scores across racial lines. # create a new environment conda_create(&quot;r-reticulate&quot;) ## [1] &quot;/home/jae/.local/share/r-miniconda/envs/r-reticulate/bin/python&quot; # install libs conda_install(&quot;r-reticulate&quot;, c(&quot;pandas&quot;)) # indicate that we want to use a specific condaenv use_condaenv(&quot;r-reticulate&quot;) from truth_tables import PeekyReader, Person, table, is_race, count, vtable, hightable, vhightable from csv import DictReader people = [] with open(&quot;./data/cox-parsed.csv&quot;) as f: reader = PeekyReader(DictReader(f)) try: while True: p = Person(reader) if p.valid: people.append(p) except StopIteration: pass pop = list(filter(lambda i: ((i.recidivist == True and i.lifetime &lt;= 730) or i.lifetime &gt; 730), list(filter(lambda x: x.score_valid, people)))) recid = list(filter(lambda i: i.recidivist == True and i.lifetime &lt;= 730, pop)) rset = set(recid) surv = [i for i in pop if i not in rset] Define a function for a table. import pandas as pd def create_table(x, y): t = table(list(x), list(y)) df = pd.DataFrame(t.items(), columns = [&#39;Metrics&#39;, &#39;Scores&#39;]) return(df) All defenders create_table(list(recid), list(surv)).to_csv(&quot;data/table_recid.csv&quot;) read.csv(here(&quot;data&quot;, &quot;table_recid.csv&quot;))[,-1] %&gt;% ggplot(aes(x = Metrics, y = Scores)) + geom_col() + labs(title = &quot;Recidivism&quot;) That number is higher for African Americans at 44.85% and lower for whites at 23.45%. def create_comp_tables(recid_data, surv_data): # filtering variables is_afam = is_race(&quot;African-American&quot;) is_white = is_race(&quot;Caucasian&quot;) # dfs df1 = create_table(filter(is_afam, recid_data), filter(is_afam, surv_data)) df2 = create_table(filter(is_white, recid_data), filter(is_white, surv_data)) # concat dfs = pd.concat([df1, df2]) dfs[&#39;Group&#39;] = [&#39;African Americans&#39;,&#39;African Americans&#39;,&#39;Whites&#39;,&#39;Whites&#39;] return(dfs) create_comp_tables(recid, surv).to_csv(&quot;data/comp_tables_recid.csv&quot;) read.csv(here(&quot;data&quot;, &quot;comp_tables_recid.csv&quot;))[,-1] %&gt;% ggplot(aes(x = Metrics, y = Scores, fill = Group)) + geom_col(position = &quot;dodge&quot;) + coord_flip() + labs(title = &quot;Recidivism&quot;) 4.4.2 Risk of violent recidivism COMPAS also offers a score that aims to measure a persons risk of violent recidivism, which has a similar overall accuracy to the Recidivism score. vpeople = [] with open(&quot;./data/cox-violent-parsed.csv&quot;) as f: reader = PeekyReader(DictReader(f)) try: while True: p = Person(reader) if p.valid: vpeople.append(p) except StopIteration: pass vpop = list(filter(lambda i: ((i.violent_recidivist == True and i.lifetime &lt;= 730) or i.lifetime &gt; 730), list(filter(lambda x: x.vscore_valid, vpeople)))) vrecid = list(filter(lambda i: i.violent_recidivist == True and i.lifetime &lt;= 730, vpeople)) vrset = set(vrecid) vsurv = [i for i in vpop if i not in vrset] create_table(vrecid, vsurv).to_csv(&quot;data/table_vrecid.csv&quot;) read.csv(here(&quot;data&quot;, &quot;table_vrecid.csv&quot;))[,-1] %&gt;% ggplot(aes(x = Metrics, y = Scores)) + geom_col() + labs(title = &quot;Violent recidivism&quot;) Even more so for Black defendants. create_comp_tables(vrecid, vsurv).to_csv(&quot;data/comp_tables_vrecid.csv&quot;) read.csv(here(&quot;data&quot;, &quot;comp_tables_vrecid.csv&quot;))[,-1] %&gt;% ggplot(aes(x = Metrics, y = Scores, fill = Group)) + geom_col(position = &quot;dodge&quot;) + coord_flip() + labs(title = &quot;Violent recidivism&quot;) "]]
