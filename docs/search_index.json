[["index.html", "Fairness and Bias in Machine Learning Workshop Chapter 1 Fairness and Bias in Machine Learning Workshop", " Fairness and Bias in Machine Learning Workshop Jae Yeon Kim Aniket Kesari Renata Barreto Avery Richard 2020-10-16 Chapter 1 Fairness and Bias in Machine Learning Workshop This workshops provides a gentle introduction to the fairness and Bias in machine Learning applications with a focus on the ProPublica’s Analysis of the COMPAS algorithm. We revised the ProPublica’s original R and Python code to increase its code readability, blend it with other references, and published and deployed the revised notebook using bookdown and GitHub page. A gif of defendants being put into an algorithm by SELMAN DESIGN Bias in the data Risk of Recidivism Data Risk of Violent Recidivism Data Bias in the algorithm For more information on the ProPublica’s Machine Bias project, we encourage to check out the following references. Argument by Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner Counterargument by Sam Corbett-Davies, Emma Pierson, Avi Feller and Sharad Goel Methodology "]]
